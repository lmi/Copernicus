{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1Fkwk7C5kuh"
   },
   "source": [
    "# ðŸŒŠ Exploring Copernicus Marine Data in Google Colab\n",
    "\n",
    "**An interactive notebook for retrieving and exploring Copernicus Marine datasets, created by NÃ¡ttÃºrufrÃ¦Ã°istofnun.**\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "This notebook connects to **Copernicus Marine Service** to retrieve and list all available datasets.\n",
    "Using Python, it fetches dataset descriptions automatically and generates markdown documentation.\n",
    "\n",
    "The script logs in Copernicus Marine using credentials and queries Copernicus Marine API for metadata.\n",
    "\n",
    "Find a full list of available products here: https://data.marine.copernicus.eu/products\n",
    "\n",
    "### How to Use\n",
    "1. Open this notebook in Google Colab or another cloud platform.\n",
    "2. Register a Copernicus Marine account here: https://data.marine.copernicus.eu/register\n",
    "3. Insert valid credentials in section Login to access the data.\n",
    "4. Run the provided code cells in sequence (do not skip cells) to explore dataset descriptions and available services, download, process and display them.\n",
    "\n",
    "| Try the code via free cloud platforms: | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lmi/Copernicus/blob/master/Marine/Overview/ConnectMarine.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "### Attribution\n",
    "- **License**: This notebook is published under **CC BY 4.0**.\n",
    "- **Citation**: \"*Credits: NÃ¡ttÃºrufrÃ¦Ã°istofnun*\"\n",
    "- **Author**: Marco Pizzolato\n",
    "- **Data Sources**: [Copernicus Marine Service](https://marine.copernicus.eu/)\n",
    "- **Created in**: Python\n",
    "\n",
    "---\n",
    "\n",
    "**This notebook provides an automated way to explore and document Copernicus Marine datasets, making ocean data more accessible.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-aVlInB5kuk"
   },
   "source": [
    "## Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNAOQ2ba5kuk"
   },
   "outputs": [],
   "source": [
    "!pip install -q copernicusmarine pandas tabulate Pillow mdutils leafmap rioxarray xarray netCDF4 rasterio pyproj localtileserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4WcF2eg5kul"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from mdutils.mdutils import MdUtils\n",
    "from mdutils.tools import Html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFd3YCIv8cLD"
   },
   "source": [
    "## Login to Copernicus Marine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tb2SvWO8e4e"
   },
   "source": [
    "Register a Copernicus Marine account here: https://data.marine.copernicus.eu/register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDauVuI35kul"
   },
   "outputs": [],
   "source": [
    "import copernicusmarine as cm\n",
    "import getpass\n",
    "\n",
    "username = input(\"Enter your Copernicus Marine username: \")\n",
    "password = getpass.getpass(\"Enter your Copernicus Marine password: \")\n",
    "\n",
    "cm.login(username=username, password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TP01cZ615kul"
   },
   "source": [
    "## Fetch Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bc1JUyXu5kul",
    "outputId": "1caebbf0-d7b8-4a48-fa61-f7fb9063f395"
   },
   "outputs": [],
   "source": [
    "catalog = cm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3l5l85F5kul",
    "outputId": "e52c8414-5052-438e-dbb9-9e818bd0f1c3"
   },
   "outputs": [],
   "source": [
    "# Inspect the structure of the first product and its datasets\n",
    "first_product = catalog.products[0]\n",
    "print(first_product.model_dump())\n",
    "print(first_product.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ag3DSZUy5kum"
   },
   "source": [
    "## Save catalog as Markdown File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIwweG4s5kum"
   },
   "outputs": [],
   "source": [
    "# Initialize the Markdown file\n",
    "md_file = MdUtils(file_name='Copernicus_Marine_Products_and_Datasets')\n",
    "\n",
    "# Iterate through products\n",
    "for product in catalog.products:\n",
    "    product_title = product.title\n",
    "    product_id = product.product_id\n",
    "    description = product.description\n",
    "    thumbnail_url = product.thumbnail_url\n",
    "\n",
    "        # Add thumbnail image if available\n",
    "    if thumbnail_url:\n",
    "        # Resize the image to 100x100 pixels using HTML\n",
    "        img_tag = Html.image(path=thumbnail_url, size='300x200')\n",
    "        md_file.new_paragraph(img_tag)\n",
    "\n",
    "    # Add an empty line after the image\n",
    "    md_file.new_paragraph('\\n')\n",
    "\n",
    "    # Add a header for the product\n",
    "    md_file.new_header(level=1, title=product_title)\n",
    "\n",
    "    # Add product ID\n",
    "    md_file.new_paragraph(f'**Product ID:** {product_id}')\n",
    "\n",
    "    # Add description\n",
    "    md_file.new_paragraph(f'**Description:** {description}')\n",
    "\n",
    "    # Add an empty line after the image\n",
    "    md_file.new_paragraph('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWgZvtvx5kum",
    "outputId": "920817c5-64b5-4ff4-a0e3-4cec32d6d248"
   },
   "outputs": [],
   "source": [
    "# Create the Markdown file\n",
    "md_file.create_md_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbr2vdhH5kum"
   },
   "source": [
    "## Display the created overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HT5-t3H5kum"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lL7M0uA05kum",
    "outputId": "1823445a-d4f0-4c60-dd7a-5955848f07fe"
   },
   "outputs": [],
   "source": [
    "# Display the generated markdown file at the end of the notebook\n",
    "n_lines = 100  # how many lines to display\n",
    "with open(\"Copernicus_Marine_Products_and_Datasets.md\", \"r\") as file:\n",
    "    content = \"\".join([next(file) for _ in range(n_lines)])\n",
    "display(Markdown(content + \"\\n\\n... *truncated*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeW951bKBeRa"
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ajcvY0E5kum"
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "# Product example: ARCTIC_ANALYSISFORECAST_BGC_002_004\n",
    "DATASET_ID = \"cmems_mod_arc_bgc_anfc_ecosmo_P1D-m\"  #  âŸµ from product page (Select one of you choice)\n",
    "\n",
    "# Small AOI covering Iceland and nearby Arctic (adjust as you wish)\n",
    "bbox = dict(\n",
    "    minimum_longitude=-40.0, maximum_longitude=40.0,\n",
    "    minimum_latitude=60.0,  maximum_latitude=85.0\n",
    ")\n",
    "\n",
    "# Use \"latest\" day that is surely produced (yesterday is safe for NRT)\n",
    "end = dt.datetime.utcnow().date()\n",
    "start = end - dt.timedelta(days=1)\n",
    "time_sel = dict(\n",
    "    start_datetime=start.isoformat(),\n",
    "    end_datetime=end.isoformat()\n",
    ")\n",
    "\n",
    "# Name of the file we download\n",
    "out_nc = \"arctic_bgc_chl.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "referenced_widgets": [
      "eb5d19fd4b494cf689d20c9845852bb3",
      "42852a4990274adaab29f39252ffbeee",
      "c433e745f21643d08d04a27461c28caf",
      "3b6b7a1519b44ffc87a50174310aa194",
      "58a71907e04145c583d934fdc34d4c88",
      "64d4c8fc269d4dd1b5a6140e4d0c6788",
      "fdd4e87cc8af4c8ebc90c19fc253d492",
      "862ea5ee81fe4395acf0f1274552afbb",
      "98dea2cd5b1e49149a0df532c7fb5132",
      "b8405145a95d4b3184a2aa8cacaebccb",
      "32628a663b774547911fc0f727899d1b"
     ]
    },
    "id": "QQysT1js9tyK",
    "outputId": "d9f3dd76-0a13-45cc-b6f4-099552ed9ac5"
   },
   "outputs": [],
   "source": [
    "# We'll ask for \"chl*\" but stay robust: if variable name differs, we'll detect it later from the file itself.\n",
    "# Request only surface layer (0 m). Many CMEMS BGC datasets use \"depth\" in meters.\n",
    "cm.subset(\n",
    "    dataset_id=DATASET_ID,\n",
    "    variables=None,                      # keep None here; weâ€™ll auto-pick \"chl\" variable after download\n",
    "    **bbox,\n",
    "    minimum_depth=0, maximum_depth=0,    # surface\n",
    "    **time_sel,\n",
    "    output_filename=out_nc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYJ-DLxsBjd5"
   },
   "source": [
    "## Convert the data to TIFF (to plot on map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "X2R36Tyi-Qii",
    "outputId": "2a94a5ec-48e1-43b8-bad5-23cea137b5b0"
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "\n",
    "ds = xr.open_dataset(out_nc, decode_times=True)\n",
    "\n",
    "# ---- Find a chlorophyll-like variable (robust to name variations)\n",
    "candidates = [v for v in ds.data_vars if (\"chl\" in v.lower()) or (\"chlor\" in v.lower())]\n",
    "if not candidates:\n",
    "    raise ValueError(f\"No chlorophyll-like variable found in {list(ds.data_vars)}\")\n",
    "var = candidates[0]\n",
    "da = ds[var]\n",
    "\n",
    "# ---- Select a single time slice (nearest to end date)\n",
    "if \"time\" in da.dims:\n",
    "    da = da.sel(time=da[\"time\"].max())\n",
    "\n",
    "# ---- Some CMEMS grids are polar stereographic with x/y & grid_mapping.\n",
    "# Try to attach CRS using the CF grid mapping, otherwise assume lat/lon.\n",
    "def write_geotiff_from_da(da, tif_path=\"arctic_bgc_chl.tif\"):\n",
    "    # If we have lat/lon coords, reproject on-the-fly by assigning EPSG:4326\n",
    "    if set([\"lat\", \"latitude\"]).intersection(da.coords) and set([\"lon\", \"longitude\"]).intersection(da.coords):\n",
    "        # Normalize coordinate names\n",
    "        lat_name = \"lat\" if \"lat\" in da.coords else \"latitude\"\n",
    "        lon_name = \"lon\" if \"lon\" in da.coords else \"longitude\"\n",
    "        da = da.rename({lat_name: \"lat\", lon_name: \"lon\"})\n",
    "        # rioxarray expects y,x order named differently; use .rio.set_spatial_dims\n",
    "        da = da.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=False)\n",
    "        da = da.rio.write_crs(4326, inplace=False)\n",
    "        da.rio.to_raster(tif_path)\n",
    "        return tif_path\n",
    "\n",
    "    # Else assume projected x/y with CF grid_mapping\n",
    "    # rioxarray can parse CRS from the grid mapping variable when present.\n",
    "    # Find 'x','y' or 'rlon','rlat' etc., normalize to x/y.\n",
    "    spatial_dims = [d for d in da.dims if d.lower() in (\"x\",\"y\",\"rlon\",\"rlat\",\"cols\",\"rows\")]\n",
    "    if len(spatial_dims) >= 2:\n",
    "        # Try to infer x/y order\n",
    "        # Prefer something like ('x','y'); else sort by \"x-like\" first\n",
    "        order = []\n",
    "        for cand in (\"x\",\"rlon\",\"cols\"):\n",
    "            if cand in da.dims: order.append(cand)\n",
    "        for cand in (\"y\",\"rlat\",\"rows\"):\n",
    "            if cand in da.dims: order.append(cand)\n",
    "        # Fallback: keep existing\n",
    "        if len(order) != 2: order = da.dims[:2]\n",
    "        da = da.rename({order[0]: \"x\", order[1]: \"y\"})\n",
    "        # Attach CRS from grid mapping if available\n",
    "        gm = da.rio.grid_mapping\n",
    "        if gm is None:\n",
    "            # As a last resort, try common polar stereographic for ARC MFC\n",
    "            # (Best effort; proper CRS comes from CF metadata.)\n",
    "            da = da.rio.write_crs(\"EPSG:3857\", inplace=False)  # Arctic Polar Stereographic\n",
    "        # Ensure spatial dims are set\n",
    "        da = da.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=False)\n",
    "        da.rio.to_raster(tif_path)\n",
    "        return tif_path\n",
    "\n",
    "    raise RuntimeError(\"Could not determine geospatial coordinates/CRS to write GeoTIFF.\")\n",
    "\n",
    "tif_path = write_geotiff_from_da(da, \"arctic_bgc_chl.tif\")\n",
    "tif_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MawjJIkRBmX5"
   },
   "source": [
    "## Display the data on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWhMqJ_R-hAG"
   },
   "outputs": [],
   "source": [
    "import leafmap\n",
    "\n",
    "# Initialize map\n",
    "m = leafmap.Map(center=[70, -20], zoom=3)\n",
    "\n",
    "# Add background layer\n",
    "m.add_basemap(\"Esri.OceanBasemap\")\n",
    "\n",
    "# Add our downloaded raster\n",
    "m.add_raster(\n",
    "    tif_path,\n",
    "    layer_name=\"Chlorophyll-a (surface)\",\n",
    "    zoom_to_layer=True,\n",
    "    colormap=\"viridis\",\n",
    "    vmin=0, # Min value for color scale\n",
    "    vmax=10 # Max value for color scale\n",
    ")\n",
    "\n",
    "# Display map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjMz7ZaHCLjN"
   },
   "source": [
    "## Display data directly from the web with no download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-nU2Fmo_dHV"
   },
   "outputs": [],
   "source": [
    "import leafmap\n",
    "\n",
    "# The layer identifier you can find them all here: https://data.marine.copernicus.eu/products\n",
    "LAYER_ID = (\"ARCTIC_ANALYSISFORECAST_BGC_002_004/\"\n",
    "            \"cmems_mod_arc_bgc_anfc_ecosmo_P1D-m_202105/chl\")\n",
    "\n",
    "# Pick any of the listed times;\n",
    "ISO_TIME = \"2025-07-01T00:00:00Z\"\n",
    "\n",
    "# Optional: elevation (depth, in meters). The default in the XML is ~ -0.494 m (surface layer in z*)\n",
    "ELEVATION = \"-0.4940253794193268\"   # or omit the &ELEVATION param to use the default\n",
    "\n",
    "# Choose a TileMatrixSet that matches your basemap (Web Mercator or WGS84)\n",
    "TMS = \"EPSG:3857\"\n",
    "\n",
    "# Server-side styling. If viridis isnâ€™t available on this layer, switch to 'cmap:matter' or use 'logScale' variant.\n",
    "STYLE = \"cmap:viridis\"      # fallback: \"cmap:matter\" or \"cmap:matter,logScale\"\n",
    "\n",
    "# Make URL\n",
    "WMTS_URL = (\n",
    "    \"https://wmts.marine.copernicus.eu/teroWmts\"\n",
    "    \"?SERVICE=WMTS&REQUEST=GetTile&VERSION=1.0.0\"\n",
    "    f\"&LAYER={LAYER_ID}\"\n",
    "    \"&FORMAT=image/png\"\n",
    "    f\"&TILEMATRIXSET={TMS}\"\n",
    "    \"&TILEMATRIX={z}&TILEROW={y}&TILECOL={x}\"\n",
    "    f\"&time={ISO_TIME}\"\n",
    "    f\"&STYLE={STYLE}\"\n",
    "    f\"&ELEVATION={ELEVATION}\"\n",
    ")\n",
    "\n",
    "# Prepare map\n",
    "m = leafmap.Map(center=[30, 0], zoom=2)\n",
    "\n",
    "# Add our WMTS layer\n",
    "m.add_tile_layer(\n",
    "    url=WMTS_URL,\n",
    "    name=\"CMEMS Zooplankton (monthly)\",\n",
    "    attribution=\"Copernicus Marine\"\n",
    ")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrnIY1mOGKMC"
   },
   "source": [
    "The difference is that on the online data served as Web Map Tile Server (WMTS) it is not possible to process the data, while on the downloaded data it is possibe to combine it with other data or extract the single pixel values."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
